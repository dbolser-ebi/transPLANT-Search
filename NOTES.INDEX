#! /usr/local/bin/bash

## SHELL SCRIPT FOR INDEXING PARTNER DATA

# Quit the script if *anything* fails!
set -o errexit # set -e

# Quit the script if we forget to initalize a variatble!
set -o nounset # set -u



## POINT AT THE INDEXES
#index_dir=Data/Indexes
#index_dir=/mnt/vbox-shared/TransPLANT_Indexes
index_dir=/nfs/production/panda/ensemblgenomes/data/Plants/TransPLANT/Indexes



## PICK YOUR SERVER (Solr version 4+)

## Testing on a farm node
 url=http://ebi1-024:8983/solr

## Local testing
#url=http://localhost:1234/solr
#url=http://dbolser-laptop.windows.ebi.ac.uk:1234/solr

## Production 
#url=http://pweb-2b:8045/solr           # V4.0-BETA (LIVE)
#url=http://pweb-2b:8046/solr           # V4.4 (STAGE/LIVE)
#url=http://ves-ebi-60:8045/solr        # V4.7 (NEW LIVE)



## Define some options common to all dumps, and add softCommit so that
## we don't have to call commit every so often...
common_opt="separator=%09&softCommit=true"



## FIRST DELETE?

# ...

## The simple way to delete an index is (typically) just:
#rm -rf solr/${core}/data/

## Deleting the data directory on a runnin instance will probably fail
## (due to NFS locks). Note, you should delete and then restart solr
## after changing the schema for any core!



## INDEX EBI:
core=transPlant-EBI

for i in ${index_dir}/EBI/transplant*-fix.tsv; do
    echo $i
    
    OPT=${common_opt}
    OPT="${OPT}&fieldnames=entry_type,database_name,db_id,db_version,name,description,url,species,feature_type,sequence_id,start_position,end_position"
    
    #OPT="${OPT}&literal.database_name=Ensembl+Plants"
    
    ## This fails (when provider = "EBI,Ensembl+Plants")
    #OPT="${OPT}&f.provider.split=true"
    #OPT="${OPT}&f.provider.separator=,"
    
    ## Nasty remapping...
    #OPT="${OPT}&f.obj_type.map=tRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=tRNA_pseudogene:ncRNA"
    #OPT="${OPT}&f.obj_type.map=miRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=ncRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=snoRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=rRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=snRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=:ncRNA"
    #OPT="${OPT}&f.obj_type.map=SRP_RNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=antisense:ncRNA"
    #OPT="${OPT}&f.obj_type.map=misc_RNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=P_RNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=RNase_MRP_RNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=tmRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=tRNA:ncRNA"
    #OPT="${OPT}&f.obj_type.map=tRNA:ncRNA"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



## INDEX IPK
core=transPlant-IPK

for i in \
    ${index_dir}/IPK/*.tsv.new \
    ${index_dir}/IPK/optimas_dw_export_101013.tsv; do
    echo $i
    
    OPT=$common_opt
    OPT="${OPT}&header=true"
    OPT="${OPT}&trim=true"
    OPT="${OPT}&fieldnames=db_id,entry_type,database_name,species,description,url"
    
    ## Split the species
    OPT="${OPT}&f.species.split=true"
    OPT="${OPT}&f.species.separator=,"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



## INDEX MIPS:
core=transPlant-MIPS

for i in ${index_dir}/MIPS/*.txt; do
    echo $i
    
    OPT=$common_opt
    OPT="${OPT}&fieldnames=db_id,entry_type,database_name,species,description,url"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo

for i in ${index_dir}/MIPS/crowsnest_refs_2014-09-01/*.tsv; do
    echo $i

    OPT=$common_opt
    OPT="${OPT}&header=true"
    OPT="${OPT}&fieldnames=entry_type,database_name,db_id,name,description,url,species,xref,feature_type,sequence_id,start_position,end_position"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



## INDEX PAS:
core=transPlant-PAS

for i in ${index_dir}/PAS/*.tab; do
    echo $i
    
    OPT=$common_opt
    OPT="${OPT}&header=true"
    OPT="${OPT}&fieldnames=db_id,entry_type,database_name,species,description,url"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



## INDEX URGI:
core=transPlant-URGI

#for i in ${index_dir}/URGI/Transplant_*.csv; do
for i in ${index_dir}/URGI/solr_dump.tsv; do
    echo $i
    
    OPT=$common_opt
    OPT="${OPT}&fieldnames=db_id,entry_type,database_name,species,description,url"
    
    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



echo DONE



## Finally, we have to stick at least some data into the 'hub' index,
## so that it reports it's fields correctly...

## We use something similar to the PAS data...

core=transPlant

for i in ${index_dir}/null_entry.tsv; do
    echo $i
    
    OPT=$common_opt
    OPT="${OPT}&header=true"
    OPT="${OPT}&fieldnames=db_id,entry_type,database_name,species,description,url"

    ## Run it
    time \
        curl "${url}/${core}/update?${OPT}" --data-binary @"${i}" \
        -H 'Content-type:application/csv'
    
done
echo; echo



## Wuh?
set +e
set +u
